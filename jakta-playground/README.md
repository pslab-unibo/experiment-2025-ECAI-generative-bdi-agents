# JaKtA Playground

## Prerequisites

Before starting, make sure you have JDK 21 or newer installed and at least Python 3.9.

To directly run a python command, you can activate the virtual environment provided that you have created it:

```shell
source build/python/bin/activate
```

## Downloading experiment data

Create a virtual environment:

```shell
../gradlew createVenv
```

Install DVC:

```shell
../gradlew installRequirements
```

This DVC project comes with a DVC [remote storage](https://dvc.org/doc/commands-reference/remote) that holds experiments' data used in the evaluation section of the thesis.

To access the remote DagsHub credentials are needed. To configure the authentication, go to the repository where the experiments are stored, [here](https://dagshub.com/rbattistini/plan-generation-experiments) while logged in DagsHub, and then go to `Remote -> Data -> DVC` and run the commands under the Setup credentials section, either directly or through Gradle, like this:

```shell
../gradlew dvc -Pargs="remote modify origin --local access_key_id <token>"
../gradlew dvc -Pargs="remote modify origin --local secret_access_key <token>"
```

Once credentials are configured, [dvc pull](https://dvc.org/doc/command-reference/pull) can be used to download the data:

```shell
../gradlew dvc -Pargs="pull"
```

This will download several gigabytes of data (~6.7 GB).

## Pushing experiment data

To set up a remote, refer to: https://dvc.org/doc/user-guide/data-management/remote-storage.
Otherwise, you can set up a local remote on your file system:

```shell
mkdir -p /tmp/dvc-storage
dvc remote add local /tmp/dvc-storage
```

You should now be able to run:

```shell
../gradlew dvc -Pargs="push -r local" --quiet
```

## Replaying an experiment

You can rerun experiments using previously recorded LLM responses and generate new execution traces.

To run an experiment with an existing LLM response and see the execution trace in your console:

```shell
../gradlew replayExperiment --args="--exp-dir experiments/deepseek/deepseek-chat-v3-0324:free-1-prompt_with_hints-0.1"
```

To run an experiment and save the new execution trace as a separate experiment:

```shell
./gradlew replayExperiment --args="--exp-dir experiments/deepseek/deepseek-chat-v3-0324:free-1-prompt_with_hints-0.1 --log-to-file"
```

The execution traces generated by the human-provided plans can be observed by running this task:

```shell
./gradlew runBaseline
```

## Running an experiment from scratch

Requires an api key for the configured provider (currently OpenRouter), otherwise another provider can be specified in the `provider` key of the `parameters.yml` file.

The key must be put in a `.env` file at the root of the repository (see `.env.template` for a reference).

This is an example run that uses the `runExperiment` task and will log results on the console and in the provided directory.

```shell
../gradlew runExperiment --args="--model-id=mistralai/mistral-small-3.2-24b-instruct:free --temperature=0.5 --max-tokens=2048 --timeout-millis=30000 --lm-server-url=https://openrouter.ai/api/v1/ --log-dir=experiments/mistralai/mistral-small-3.2-24b-instruct:free --log-to-file"
```

To use the DVC pipeline, adjust the `parameters.yml` file if needed and run:

```shell
../gradlew dvc -Pargs="exp run" --quiet
# or if committing new results
../gradlew dvc -Pargs="repro" --quiet
```

## Evaluation

The `analyzePGP` Gradle task can be used to see the messages exchanged with an LLM as part of a PGP and optionally to compute metrics.

An example of use is shown below:

```shell
# replace <runId> with the uuid created by an experiment run or replay
../gradlew analyzePGP --args="--exp-dir experiments/mistralai/mistral-small-3.2-24b-instruct:free/<runId>/ --compute-metrics"
```

The metrics computed are:
- Plan Count (PC): Total number of generated plans.
- Context Complexity (CC): Average number of beliefs per plan context.
- Plan Body Complexity (PBC): Average number of operations per plan body.
- Generalization Count (GC): Number of generated plans that use variables (general) rather than constants (specific).
- Redundancy Amount (RA): Number of generated plans which are useless (e.g., not executable at runtime or subsumed by more general plans).
- Novel Goal Count (NGC): Number of newly invented goals.
- Novel Belief Count (NBC): Number of newly invented beliefs.
- Goal Semantic Misalignment (GSM): Number of semantically misaligned uses of admissible goals.
- Belief Semantic Misalignment (BSM): Number of semantically misaligned uses of admissible beliefs.
- Task Success Rate (TSR): Percentage of experiments where the agent successfully achieves the !reach(home) goal.
- Goal Achievement Time (GAT): Steps required to reach the goal in successful runs.

The results are stored in a hierarchy, where experiments are organized first by model provider and variant (mistralai/mistral-small-3.2-24b-instruct:free-1), then by nested experiment components using UUID-based naming. The files use a pattern of [Mas-UUID]-[AgentName-UUID]-[PgpName-UUID] to create a tree-like structure: starting with the id of the mas (Mas-2c1f5f76...), then adding the agent with its own UUID, and finally including each PGP attempt like "angry_blackburn" with their UUID.
Each level generates both .jsonl files (containing structured experiment data) and .log files (containing execution logs).

```
jakta-playground/experiments
└── mistralai
    └── mistral-small-3.2-24b-instruct:free-1
        ├── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1-ExplorerRobot-b4b887ab-758d-4c5a-9e2c-f6bcfea199c0-angry_blackburn-b34f2c7d-caf6-4b0b-afbe-e69e9e981575.jsonl
        ├── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1-ExplorerRobot-b4b887ab-758d-4c5a-9e2c-f6bcfea199c0-angry_blackburn-b34f2c7d-caf6-4b0b-afbe-e69e9e981575.log
        ├── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1-ExplorerRobot-b4b887ab-758d-4c5a-9e2c-f6bcfea199c0.jsonl
        ├── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1-ExplorerRobot-b4b887ab-758d-4c5a-9e2c-f6bcfea199c0.log
        ├── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1.jsonl
        └── Mas-2c1f5f76-13d0-49d4-847f-d456cd08f0d1.log
```


For more information, refer to the Evaluation chapter of the thesis.
